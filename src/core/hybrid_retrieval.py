import fitz  # PyMuPDF
import numpy as np
from typing import List, Tuple, Dict
from .test_qwen3_embedding import Qwen3Embedding
from test_qwen3_reranker import Qwen3Reranker
import torch
import re

class HybridPDFRetriever:
    def __init__(self, 
                 embedding_model_path: str = "models/Qwen3-Embedding-0.6B/Qwen/Qwen3-Embedding-0.6B",
                 reranker_model_path: str = "models/Qwen3-Reranker-0.6B/Qwen/Qwen3-Reranker-0.6B"):
        """
        åˆå§‹åŒ–æ··åˆPDFæ£€ç´¢å™¨
        Args:
            embedding_model_path: Qwen3 Embeddingæ¨¡å‹è·¯å¾„
            reranker_model_path: Qwen3 Rerankeræ¨¡å‹è·¯å¾„
        """
        print("æ­£åœ¨åŠ è½½Qwen3 Embeddingæ¨¡å‹...")
        self.embedding_model = Qwen3Embedding(embedding_model_path)
        print("Embeddingæ¨¡å‹åŠ è½½å®Œæˆï¼")
        
        print("æ­£åœ¨åŠ è½½Qwen3 Rerankeræ¨¡å‹...")
        self.reranker_model = Qwen3Reranker(
            model_name_or_path=reranker_model_path,
            instruction="Given the user query, retrieval the relevant passages",
            max_length=2048
        )
        print("Rerankeræ¨¡å‹åŠ è½½å®Œæˆï¼")
        
        self.documents = []
        self.embeddings = None
        self.chunk_size = 300
        
    def load_pdf(self, pdf_path: str) -> List[str]:
        """åŠ è½½PDFæ–‡ä»¶å¹¶æå–æ–‡æœ¬"""
        print(f"æ­£åœ¨åŠ è½½PDFæ–‡ä»¶: {pdf_path}")
        
        try:
            doc = fitz.open(pdf_path)
            full_text = ""
            
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                text = page.get_text()
                full_text += f"ç¬¬{page_num + 1}é¡µ: " + text + "\n"
            
            doc.close()
            
            self.documents = self._split_text(full_text)
            print(f"æˆåŠŸæå– {len(self.documents)} ä¸ªæ–‡æœ¬å—")
            
            return self.documents
            
        except Exception as e:
            print(f"åŠ è½½PDFæ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def _split_text(self, text: str) -> List[str]:
        """å°†æ–‡æœ¬åˆ†å‰²æˆå°å—"""
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿï¼›\n]', text)
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            if len(current_chunk) + len(sentence) <= self.chunk_size:
                current_chunk += sentence + "ã€‚"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + "ã€‚"
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def build_embeddings(self):
        """ä¸ºæ‰€æœ‰æ–‡æ¡£æ„å»ºå‘é‡è¡¨ç¤º"""
        if not self.documents:
            print("æ²¡æœ‰æ–‡æ¡£å¯ä»¥æ„å»ºå‘é‡")
            return
            
        print("æ­£åœ¨æ„å»ºæ–‡æ¡£å‘é‡...")
        with torch.inference_mode():
            self.embeddings = self.embedding_model.encode(self.documents, is_query=False)
        print("æ–‡æ¡£å‘é‡æ„å»ºå®Œæˆ")
        
        # è¾“å‡ºå‰10ä¸ªæ–‡æ¡£å‘é‡çš„ä¿¡æ¯å’Œå­˜å‚¨åœ°å€
        print(f"\nğŸ“Š æ–‡æ¡£å‘é‡ä¿¡æ¯:")
        print(f"   æ€»æ–‡æ¡£æ•°é‡: {len(self.documents)}")
        print(f"   å‘é‡ç»´åº¦: {self.embeddings.shape[1]}")
        print(f"   å‘é‡æ•°æ®ç±»å‹: {self.embeddings.dtype}")
        print(f"   å‘é‡å­˜å‚¨è®¾å¤‡: {self.embeddings.device}")
        print(f"   å‘é‡å†…å­˜åœ°å€: {hex(id(self.embeddings))}")
        
        # è¾“å‡ºå‰10ä¸ªæ–‡æ¡£å‘é‡çš„å†…å®¹
        print(f"\nğŸ” å‰10ä¸ªæ–‡æ¡£å‘é‡å†…å®¹:")
        for i in range(min(10, len(self.documents))):
            vector = self.embeddings[i]
            print(f"   æ–‡æ¡£{i+1} (ç´¢å¼•{i}):")
            print(f"     å‘é‡å½¢çŠ¶: {vector.shape}")
            print(f"     å‘é‡å‰5ä¸ªå€¼: {vector[:5].cpu().numpy()}")
            print(f"     å‘é‡å5ä¸ªå€¼: {vector[-5:].cpu().numpy()}")
            print(f"     å‘é‡å‡å€¼: {vector.mean().item():.6f}")
            print(f"     å‘é‡æ ‡å‡†å·®: {vector.std().item():.6f}")
            print(f"     å‘é‡L2èŒƒæ•°: {torch.norm(vector).item():.6f}")
            print(f"     å¯¹åº”æ–‡æ¡£å†…å®¹: {self.documents[i][:100]}...")
            print()
    
    def hybrid_search(self, query: str, top_k_embedding: int = 10, top_k_final: int = 5) -> List[Tuple[str, float, int]]:
        """
        æ··åˆæ£€ç´¢ï¼šEmbeddingç²—ç­› + Rerankerç²¾ç­›
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k_embedding: Embeddingé˜¶æ®µè¿”å›çš„å€™é€‰æ•°é‡
            top_k_final: æœ€ç»ˆè¿”å›çš„ç»“æœæ•°é‡
        Returns:
            ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«(æ–‡æ¡£å†…å®¹, ç›¸å…³æ€§åˆ†æ•°, æ–‡æ¡£ç´¢å¼•)
        """
        if self.embeddings is None:
            print("è¯·å…ˆè°ƒç”¨ build_embeddings() æ„å»ºæ–‡æ¡£å‘é‡")
            return []
        
        print(f"æ­£åœ¨è¿›è¡Œæ··åˆæ£€ç´¢: {query}")
        print("="*50)
        
        # ç¬¬ä¸€é˜¶æ®µï¼šEmbeddingç²—ç­›
        print("ç¬¬ä¸€é˜¶æ®µï¼šEmbeddingç²—ç­›")
        with torch.inference_mode():
            query_embedding = self.embedding_model.encode([query], is_query=True)
        
        similarities = torch.mm(query_embedding, self.embeddings.T)
        similarities = similarities.squeeze().cpu().numpy()
        
        # è·å–top-kå€™é€‰
        top_indices = np.argsort(similarities)[::-1][:top_k_embedding]
        candidates = [(self.documents[idx], similarities[idx], idx) for idx in top_indices]
        
        print(f"Embeddingé˜¶æ®µæ‰¾åˆ° {len(candidates)} ä¸ªå€™é€‰æ–‡æ¡£:")
        for i, (doc, score, idx) in enumerate(candidates, 1):
            print(f"  å€™é€‰{i}: ç›¸ä¼¼åº¦={score:.4f}, ç´¢å¼•={idx}")
            print(f"    å†…å®¹: {doc[:80]}...")
        
        # ç¬¬äºŒé˜¶æ®µï¼šRerankerç²¾ç­›
        print(f"\nç¬¬äºŒé˜¶æ®µï¼šRerankerç²¾ç­›")
        if len(candidates) > 0:
            # æ„å»ºæŸ¥è¯¢-æ–‡æ¡£å¯¹
            pairs = [(query, doc) for doc, _, _ in candidates]
            
            # ä½¿ç”¨Rerankerè®¡ç®—ç›¸å…³æ€§åˆ†æ•°
            reranker_scores = self.reranker_model.compute_scores(pairs)
            
            # ç»„åˆç»“æœ
            reranked_results = []
            for i, (doc, embedding_score, idx) in enumerate(candidates):
                reranker_score = reranker_scores[i]
                reranked_results.append((doc, reranker_score, idx, embedding_score))
            
            # æŒ‰Rerankeråˆ†æ•°æ’åº
            reranked_results.sort(key=lambda x: x[1], reverse=True)
            
            print(f"Rerankeré˜¶æ®µé‡æ–°æ’åºç»“æœ:")
            for i, (doc, reranker_score, idx, embedding_score) in enumerate(reranked_results, 1):
                print(f"  æ’åº{i}: Rerankeråˆ†æ•°={reranker_score:.4f}, Embeddingåˆ†æ•°={embedding_score:.4f}, ç´¢å¼•={idx}")
                print(f"    å†…å®¹: {doc[:80]}...")
            
            # è¿”å›æœ€ç»ˆç»“æœ
            final_results = [(doc, reranker_score, idx) for doc, reranker_score, idx, _ in reranked_results[:top_k_final]]
            return final_results
        
        return []
    
    def embedding_only_search(self, query: str, top_k: int = 5) -> List[Tuple[str, float, int]]:
        """ä»…ä½¿ç”¨Embeddingçš„æœç´¢"""
        if self.embeddings is None:
            print("è¯·å…ˆè°ƒç”¨ build_embeddings() æ„å»ºæ–‡æ¡£å‘é‡")
            return []
        
        print(f"ä»…ä½¿ç”¨Embeddingæœç´¢: {query}")
        
        with torch.inference_mode():
            query_embedding = self.embedding_model.encode([query], is_query=True)
        
        similarities = torch.mm(query_embedding, self.embeddings.T)
        similarities = similarities.squeeze().cpu().numpy()
        
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            score = float(similarities[idx])
            doc_content = self.documents[idx]
            results.append((doc_content, score, idx))
        
        return results
    
    def reranker_only_search(self, query: str, top_k: int = 5) -> List[Tuple[str, float, int]]:
        """ä»…ä½¿ç”¨Rerankerçš„æœç´¢ï¼ˆå¯¹æ‰€æœ‰æ–‡æ¡£ï¼‰"""
        print(f"ä»…ä½¿ç”¨Rerankeræœç´¢: {query}")
        
        if len(self.documents) == 0:
            print("æ²¡æœ‰æ–‡æ¡£å¯ä»¥æœç´¢")
            return []
        
        # æ„å»ºæ‰€æœ‰æŸ¥è¯¢-æ–‡æ¡£å¯¹
        pairs = [(query, doc) for doc in self.documents]
        
        # ä½¿ç”¨Rerankerè®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        reranker_scores = self.reranker_model.compute_scores(pairs)
        
        # ç»„åˆç»“æœå¹¶æ’åº
        results = []
        for i, (doc, score) in enumerate(zip(self.documents, reranker_scores)):
            results.append((doc, score, i))
        
        results.sort(key=lambda x: x[1], reverse=True)
        return results[:top_k]

def main():
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever = HybridPDFRetriever()
    
    # åŠ è½½PDF
    pdf_path = r"C:\Users\sanrome\Documents\ä¸‰éƒç™½åº•é€šç”¨ç®€å†-zh.pdf"
    documents = retriever.load_pdf(pdf_path)
    if not documents:
        print("PDFåŠ è½½å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return
    
    # æ„å»ºå‘é‡
    retriever.build_embeddings()
    
    print("\n" + "="*80)
    print("=== æ··åˆæ£€ç´¢ç³»ç»Ÿæµ‹è¯• ===")
    print("="*80)
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "å¼ ä¸‰çš„å·¥ä½œç»éªŒ",
        "æŠ€æœ¯æŠ€èƒ½å’Œç¼–ç¨‹è¯­è¨€",
        "åº”è˜çš„å²—ä½å’Œå…¬å¸",
        "æµ‹è¯•å’Œå¼€å‘ç»éªŒ"
    ]
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"æŸ¥è¯¢: {query}")
        print(f"{'='*60}")
        
        # 1. ä»…Embeddingæœç´¢
        print("\n1ï¸âƒ£ ä»…Embeddingæœç´¢:")
        embedding_results = retriever.embedding_only_search(query, top_k=3)
        for i, (doc, score, idx) in enumerate(embedding_results, 1):
            print(f"  ç»“æœ{i}: ç›¸ä¼¼åº¦={score:.4f}, ç´¢å¼•={idx}")
            print(f"    å†…å®¹: {doc[:100]}...")
        
        # 2. ä»…Rerankeræœç´¢
        print("\n2ï¸âƒ£ ä»…Rerankeræœç´¢:")
        reranker_results = retriever.reranker_only_search(query, top_k=3)
        for i, (doc, score, idx) in enumerate(reranker_results, 1):
            print(f"  ç»“æœ{i}: ç›¸å…³æ€§={score:.4f}, ç´¢å¼•={idx}")
            print(f"    å†…å®¹: {doc[:100]}...")
        
        # 3. æ··åˆæœç´¢
        print("\n3ï¸âƒ£ æ··åˆæœç´¢ (Embedding + Reranker):")
        hybrid_results = retriever.hybrid_search(query, top_k_embedding=5, top_k_final=3)
        for i, (doc, score, idx) in enumerate(hybrid_results, 1):
            print(f"  ç»“æœ{i}: æœ€ç»ˆç›¸å…³æ€§={score:.4f}, ç´¢å¼•={idx}")
            print(f"    å†…å®¹: {doc[:100]}...")

if __name__ == "__main__":
    main() 